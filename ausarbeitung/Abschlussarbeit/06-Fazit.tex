\chapter{Fazit}

\section{Zusammenfassung}
Im Rahmen dieser Arbeit wurden verschiedene Methoden zur Extraktion von Entitäten aus natürlichsprachlichen Texten untersucht und miteinander verglichen. Es wurden außerdem verschiedene Datenquellen für Trainingskorpora verglichen, sowohl mithilfe von den Linguisten als auch automatisch erzeugte. Es wurde anschließend eine Erweiterung für das Stanbol-Framework entwickelt, die die Extraktion von Entitäten aus deutschsprachigen Suchergebnisseiten ermöglicht und es wurde eine Benutzerevaluierung durchgeführt, die zeigen sollte, ob die Extraktion von Entitäten den Benutzer bei der Suche tatsächlich unterstützen könnte. 

Die Untersuchung von möglichen Algorithmen der Extraktion von Entitäten hat gezeigt, dass die Algorithmen, die sonst für Klassifizierung verwendet werden, auch für die NER-Aufgabe eingesetzt werden können - es müssen lediglich korrekte ,,Eigenschaften`` von Wörtern (Features) ausgewählt werden, mit deren Hilfe dem Wort eine Klasse zugeordnet werden könnte. Dabei müssen die Eigenschaften nicht unbedingt von Menschen definiert werden (supervised Features), sondern können auch automatisch berechnet werden (unsupervised Features).

Die Wichtigkeit von einem richtigen Training-Korpus für eine erfolgreiche Erkennung von den Entitäten lässt sich nicht von der Hand zu weisen - es ist sehr wichtig, dass das verwendete Korpus folgende Eigenschaften besitzt:
\begin{enumerate}
\item Das verwendete Korpus soll groß genug sein, damit das Modell genug Daten fürs Training hat.
\item Das Korpus soll eine gute Qualität haben - das bedeutet, dass alle Entitäten, die im Korpus vorkommen, auch wirklich markiert sind, und zwar richtig (eine Person soll als eine Person, und nicht als eine Firma annotiert werden), dass die Sätze korrekt getrennt sind, und dass es keine nicht-Entitäten markiert werden.
\item Aus dem zweiten Punkt folgt, dass das Korpus im besten Fall von den Linguisten erstellt werden soll.
\end{enumerate}

Leider erfüllen die frei verfügbare Korpora fast immer nur das erste Kriterium - einige von denen sind automatisch generiert, bei anderen fehlt die Unterscheidung zwischen verschiedenen Klassen von Entitäten und es nur bekannt ist, ob ein bestimmtes Wort eine Entität ist, die Klasse bleibt aber unbekannt. Diese Einschränkung hat selbstverständlich auch diese Arbeit beeinflusst, und die Qualität von dem Framework war eigentlich schlechter als die sein könnte. Deswegen soll bei akademischen Werken auch ökonomische Faktoren berücksichtigt werden - da frei verfügbare Korpora nicht unbedingt eine gute Qualität aufzeigen können, sollte gelegentlich eine Option der Finanzierung eines passenden Korpus im Kauf genommen werden. 

Die Benutzerstudie hat gezeigt, dass der Einsatz von Entitäten bei der Websuche für den Benutzer theoretisch hilfreich sein könnte, allerdings müssen sowohl das Framework (Backend) als auch das User-Interface (Frontend) weiter entwickelt und verbessert werden, um eine genügende Unterstützung bei der Suche gewährleisten zu können. Es wurde festgestellt, dass die in den Entitäten vorhandene Informationen für den Benutzer nicht nur hilfreich, sondern auch störend sein können, falls es zu viele davon gibt.

Das Training eines Modell für die Erkennung von Entitäten stellt eine getrennte Aufgabe dar, die bei einigen Algorithmen (SVM) einen großen Rechenaufwand benötigt und bis auf mehrere Tage in Anspruch nehmen kann. Das Training ist mehr aufwendig und nimmt mehr Rechnerzeit in Anspruch als der Einsatz eines trainierten Modells. Die Indexierung einer Wissensdatenbank benötigt auch einen größeren Aufwand und kann bis auf eine Woche in Anspruch nehmen. Deswegen sollen bei Bedarf fürs Training von den NER-Modellen und für die Indexierung von Wissensdatenbanken getrennte Rechnereinheiten zur Verfügung gestellt werden, die leistungsfähiger als Maschinen für das System selbst sein sollten.   

Am Anfang der Arbeit gab es Befürchtungen, dass:
\begin{enumerate}
\item Aus den kurzen Suchsnippets keine Entitäten extrahiert werden könnten und man auf volle Texte der Webseite zugreifen müsste, was eine deutliche Verlängerung der Bearbeitungszeit der Benutzeranfrage bedeuten würde.
\item Die Bearbeitungszeit der Anfrage so lange sein würde, dass die Benutzer die Suche abbrechen.
\end{enumerate}
Diese Befürchtungen wurden während der Arbeit allerdings nicht bestätigt, und auch wenn es in dem Kapitel ,,Evaluierung`` beschriebene Einschränkungen gab, können die aus den kurzen Snippets extrahierte Entitäten tatsächlich für die Benutzerunterstützung eingesetzt werden. 

\section{Ausblick und Verbesserungsvorschläge}
Nachdem die Ergebnisse der Studie analysiert und zusammengefasst wurden, kommt die Frage, ob das System sich verbessern lässt und wie genau könnten die beschriebene Mängel beseitigt oder umgegangen werden.

Zuerst sollte das Problem von ,,unpassenden`` oder im Text vorhandenen aber nicht gefundenen Entitäten angegangen werden. Auf den ersten Blick würde sich dieses Problem durch Verwendung von größeren und besser strukturierten Korpora fürs Training des Modells lösen lassen, was allerdings das Hauptproblem - die Individualität von den Begriffen ,,passend`` und ,,unpassend`` nicht beseitigen kann.

Um das Problem von individuellen Vorstellungen des Benutzers bezüglich ,,Qualität`` von extrahierten Entitäten umzugehen, wäre folgende Lösung zumutbar: wie erwähnt, werden extrahierte Entitäten bevor die an den Snippet angehängt und zu dem Benutzer geschickt werden durch ein Filter anhand ihres Gewichtes herausgefiltert - alle Entitäten, deren Gewicht kleiner als $n$ ist, werden dem Benutzer nicht angezeigt. Da in dem entwickelten System dieses Schwellwert von dem Entwickler statisch festgesetzt wird, kommt es oft vor, dass entweder ,,unwichtige`` Entitäten angezeigt werden oder dass ,,wichtige`` Entitäten weggeworfen werden. Dieser Wert muss allerdings nicht unbedingt fest sein, und kann mithilfe einer Rückkopplung dynamisch angepasst werden, auf zwei Arten und Weisen:
\begin{enumerate}
\item Jeder Benutzer bekommt einen personalisierten Schwellwert. Der Vorteil dieser Methode ist, dass solche Suche wirklich ,,personalisiert`` sein würde. Der Nachteil wäre die Notwendigkeit, den Benutzer zu identifizieren, was eine anonyme Suche ausschließt. 
\item Um eine anonyme Suche gewährleisten zu können und um gleichzeitig den Schwellwert für den Entitätsfilter anpassen zu können könnte folgende Lösung angewendet werden: der Schwellwert wird zwar dynamisch angepasst, wird aber für alle Benutzer gleich sein. Solche Problemlösung würde zwar nicht so effektiv sein, wie die mit den personalisierten Schwellwerten, soll aber bessere Ergebnisse als der von dem Entwickler statisch gewählte Schwellwert aufzeigen können.
\end{enumerate}
In beiden Fällen könnte der Schwellwert mithilfe von der Frage, welche aus den gefundenen Entitäten der Benutzer für relevant und welche für irrelevant hält, angepasst werden. Die Frage könnte dem Benutzer entweder nach jeder Suche oder über eine gesonderte Einstellungsseite gestellt werden.

Ein dynamischer Schwellwert für den Entitätsfilter hätte das Problem von den entweder überflüssigen oder fehlenden Daten, die mit den extrahierten Entitäten verlinkt werden, aber nicht lösen können. Um diesen Mangel zu beseitigen, könnten eventuell folgende Schritte unternommen werden:
\begin{itemize}
\item Die offensichtlichste Lösung für fehlende Daten würde die Erweiterung von der Wissensdatenbank sein. Da Stanbol-Framework dem Entwickler die Möglichkeit gibt, mehrere Datenbanken als Quelle für die Ontologien einzusetzen, wäre eine Anbindung von neuen Wissensdatenbanken leicht realisierbar. Dabei kann auch bei Bedarf das Domain der Suche, das für die Benutzer relevant ist, berücksichtigt werden, und eine spezialisierte Wissensdatenbank (z. B. für die Krankheitsnamen oder für die Arzneimittel) eingesetzt werden.
\item Um das Problem von überflüssigen Informationen lösen zu können, würde Analyse der Suchanfrage des Benutzers nützlich sein können, damit man anhand aus der \textbf{Suchanfrage} extrahierten Informationen auswählen könnte, welche Eigenschaften der Entität angezeigt werden müssen. Zum Beispiel, wenn der Benutzer in seiner Anfrage nach dem Alter einer Person fragt, müssen:
\begin{itemize}
\item Möglicherweise nur Entitäten angezeigt werden, die die Klasse ,,Person`` haben.
\item Für jede Entität sollen nur Eigenschaften ,,,Geburts- und Todesdatum`` angezeigt werden.
\end{itemize}
\end{itemize}

Um das Problem einer richtig aufgebauten Benutzeroberfläche zu lösen, müssen weitere Benutzerstudien durchgeführt werden, man kann aber schon jetzt anhand von den einigen Benutzerfeedbacks\ref{app:feedbacks} sagen, dass die Verwendung von Tags hilfreich sein könnte.

Im Ausblick bleiben noch folgende Fragen offen, die allerdings nicht im Rahmen dieser Arbeit beantwortet werden sollen, sondern für Nachfolgewerke vorgesehen sein könnten:
\begin{itemize}
\item Welche graphische Darstellung von extrahierten Entitäten kann die beste Benutzerunterstützung gewährleisten? Wäre eine baumartige Struktur besser, als eine flache Liste? Könnte eine personalisierte Darstellung, wo der Benutzer die Knoten, die Entitäten darstellen sollen, manuell verschieben und einordnen kann, hilfreich sein? Wie geht man mit der hierarchischen Struktur von Entitäten am Besten um? Wie können die Eigenschaften, die keine Zeichenketten sind (wie Bilder), am Besten angezeigt werden?
\item Welche Möglichkeiten zur Optimierung sowohl von Extraktion als auch von Training es gibt? Kann eine Verteilung auf mehrere Rechnereinheiten etwas bringen? Könnte der Einsatz von GPU für die Berechnungen sowohl Training des Modells als auch die Suche beschleunigen?
\item Wie lässt sich die Extraktion von Entitäten mit den diversen Einsätzen für die Personalisierung der Websuche kombinieren? Wie kann man am Besten die Informationen für die Berechnung von persönlichen Gewichten für Stanbol extrahieren lassen? Wäre es auch ohne direkten Feedback möglich?
\end{itemize}